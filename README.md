# Automated Robotic Arm Grasping and Large Model Empowered Pharmacy Drug Recognition System Based on RDK X5 High-Performance Computing

## üåü Project Overview and Background

This project, "Automated Robotic Arm Grasping and Large Model Empowered Pharmacy Drug Recognition System Based on RDK X5 High-Performance Computing," aims to establish an innovative, highly intelligent solution for pharmacy drug recognition and automated dispensing. Currently, global challenges such as pharmacist shortages, low pharmacy operational efficiency, and a high incidence of manual dispensing errors are becoming increasingly prominent, directly impacting the quality of medical services and patient medication safety. In response to these urgent needs, this system has been developed.

At its core, the system relies on the RDK X5 high-performance computing platform, deeply integrating the powerful cognitive abilities of advanced large language models in natural language understanding and knowledge reasoning with the precise execution capabilities of high-accuracy robotic arms. Through this deep integration and synergy of software and hardware, this project seeks to revolutionize traditional pharmacy workflows, achieving fully automated operations from intelligent consultation and multimodal drug recognition to precise robotic grasping. The ultimate goal is to significantly enhance pharmacy operational efficiency and dispensing accuracy, alleviate the burden on pharmacists, reduce medication error risks, and lay a solid foundation for future smart healthcare systems. This system possesses broad application prospects and robust scalability, poised to become a significant driving force in the field of smart healthcare.

## ‚ú® Detailed Core Functions

This system implements three key functional modules that work collaboratively to provide a comprehensive smart pharmacy solution:

1.  **Intelligent Symptom Analysis and Personalized Medication Recommendation**:
    * **Large Language Model Driven**: The system's foundation is built upon a large language model extensively trained with medical domain knowledge, granting it exceptional natural language understanding capabilities. This allows the system to accurately parse complex symptoms described by users in colloquial, unstructured language.
    * **Semantic Analysis and Knowledge Reasoning**: The model performs in-depth semantic analysis of user-inputted symptom descriptions, combining this with a medical knowledge graph and drug database for reasoning. This process generates a personalized, scientifically sound, and precise medication recommendation list.
    * **Intelligent Interaction and Safety Assurance**: For ambiguous, uncertain, or incomplete information in user descriptions, the system incorporates an intelligent "probing" mechanism. Through guided dialogues, it acquires crucial additional details, ensuring an accurate understanding of user needs and significantly enhancing the accuracy and safety of medication recommendations, effectively preventing misdiagnosis.
2.  **Multimodal Fusion for High-Precision Drug Recognition**:
    * **Visual and Textual Dual Perception**: This project innovatively applies multimodal fusion technology for drug recognition. The system simultaneously and in parallel analyzes both the visual characteristics of drug packaging (e.g., unique shapes, colors, brand logos, typography) and the critical textual information printed on the packaging (e.g., drug name, generic name, dosage, batch number, production date).
    * **Optimized Deep Vision Model**: Utilizing a deep vision model based on the YOLOv8n architecture, which has undergone meticulous training and optimization with a vast dataset of drug images. This enables the system to perform accurate and efficient differentiation and recognition even when dealing with drugs that are visually highly similar, have similar colors, or only subtle differences (e.g., the same drug name but different dosage strengths), effectively eliminating dispensing errors at the source.
3.  **High-Precision Intelligent Grasping and Path Planning**:
    * **RDK X5 Real-time Computing Support**: Leveraging the powerful real-time processing capabilities of the RDK X5 high-performance computing platform, the system achieves intelligent, high-precision grasping control of the robotic arm. This platform can instantaneously process image recognition results and generate precise robotic arm movement commands.
    * **Pioneering Hand-Eye Calibration Algorithm**: Through the project's unique three-point calibration method, the system can map the precise spatial coordinates of recognized drugs from visual data to the robotic arm's operational space with high accuracy. This innovative algorithm not only reduces traditional calibration steps by 70% but also enhances hand-eye calibration accuracy by 4 times, ensuring millimeter-level positioning precision for the robotic arm during grasping.
    * **Dynamic Obstacle Avoidance and Efficient Execution**: Integrated with a dynamic obstacle avoidance algorithm, the robotic arm can continuously receive real-time visual feedback from the camera. Based on this, it can online optimize its motion trajectory to intelligently circumvent potential obstacles (e.g., newly placed items, environmental changes), ensuring safe, efficient, and smooth operation. The system supports both voice and text multimodal control, achieving a stable grasping success rate of over 99% in practical applications.

## üåê Broad Application Areas and Social Value

This intelligent system demonstrates immense potential across various medical scenarios, poised to bring profound positive impacts to society:

* **Comprehensive Upgrade of Smart Hospital Pharmacies**:
    * Enables fully intelligent and automated management, from patient symptom input and smart recommendation to automated drug dispensing.
    * Proven in trials to increase the daily prescription processing volume of pharmacies by over 3 times, while simultaneously reducing the dispensing error rate to below 0.1%, significantly boosting pharmacy operational efficiency and patient medication safety.
* **Empowerment of Grassroots Medical Facilities**:
    * Effectively addresses the common shortage of professional pharmacists in community clinics and rural health centers.
    * The system can provide basic automated drug dispensing and intelligent medication guidance services, enhancing the accessibility, professionalism, and standardization of grassroots medical care.
* **Emergency Medical and Unattended Pharmacies**:
    * Supports 24-hour unattended operation, enabling rapid and precise sorting of emergency drugs in critical situations.
    * In disaster relief, public health emergencies, or remote areas, the system can complete precise sorting and delivery of emergency medications within 5 seconds, gaining crucial time for life-saving efforts.
* **Personalized Medicine and Digital Health Ecosystem**:
    * The system possesses strong compatibility, allowing seamless integration with existing electronic health record (EHR) systems and other medical information platforms.
    * By combining comprehensive individual health data, medication history, and allergy information, the system can provide more refined and personalized medication plans, serving as a vital component in advancing precision medicine and the digital health ecosystem.

## ‚öôÔ∏è System Architecture and Technical Implementation

This system is a tightly integrated, intelligent closed-loop system, primarily composed of three core parts: user interaction, perception and intelligence, and execution, along with supporting data and knowledge bases. The entire system centers around the RDK X5 high-performance computing platform, achieving fully automated operations from understanding user intent to precise drug grasping.

### Hardware Components

* **RDK X5 High-Performance Computing Platform**: Serving as the "brain" and computational core of the entire system, the RDK X5 is responsible for running all complex visual and language models. It can process vast amounts of image data at high speed in real-time, accurately identify drugs, perform in-depth symptom analysis, and rapidly generate medication recommendations, forming the cornerstone of the system's intelligence.
* **USB High-Definition Camera**: Positioned above the robotic arm's workspace, it continuously captures clear, high-resolution images of all drugs on the table. These images serve as essential high-quality input for visual recognition, localization, and analysis, directly impacting the system's recognition accuracy.
* **Microphone and Audio Output Module**: Responsible for the front-end and back-end of human-computer interaction. The microphone accurately picks up user voice commands and symptom descriptions; the audio output module clearly conveys system feedback, medication recommendations, and other information to the user in audible form, enabling a natural and fluent voice dialogue experience.
* **Vacuum Suction Pump**: A critical end-effector of the robotic arm, it precisely generates and controls negative pressure to securely grasp target drugs. This grasping method ensures reliability while preventing any mechanical damage to the drug packaging, making it suitable for drugs with various packaging shapes.
* **Six-Degree-of-Freedom Robotic Arm**: Equipped with 6 degrees of freedom and driven by high-precision servo motors, it receives precise motion commands from the RDK X5. Its high flexibility and accuracy allow it to navigate obstacles within the workspace and move precisely to designated positions, completing complex operations such as grasping, placing, and sorting drugs.

### Software Modules

* **ASR (Automatic Speech Recognition) Module**: Responsible for accurately and rapidly converting user voice signals (including symptom descriptions, operational commands, etc.) picked up by the microphone into standard text, providing reliable text input for subsequent language model processing and system control.
* **Language Model Module**: Receives the text input of symptoms converted by the ASR module and, in conjunction with the system's internal medical knowledge base and drug database, performs in-depth semantic analysis, disease inference, and medication logic judgment. This module can filter and output drug names that effectively treat the corresponding symptoms based on user symptoms and available drug lists, and provide detailed medication guidance.
* **Visual Model Module**: The core utilizes an advanced deep detection model based on the YOLOv8n architecture. Through extensive annotation and training on drug package images from various angles and lighting conditions, this module can precisely identify the position and category of drug packages, and in real-time return the coordinates of the drug package in the image as well as the corresponding robotic arm coordinates for that viewing angle, providing crucial visual information for precise robotic arm grasping.
* **Robotic Arm and Suction Pump Control Interface Module**: Utilizing the underlying API functions provided by Elephant Robotics, this module is responsible for receiving precise coordinate information from the visual model. It then combines this with the innovative hand-eye calibration algorithm (which efficiently converts image coordinates into executable robotic arm motion coordinates). This module precisely controls the robotic arm's movement trajectory and posture, and intelligently manages the activation and deactivation of the suction pump, completing the precise grasping, transfer, and placement of drugs.

## üí° Key Innovations and Technological Breakthroughs

This project has achieved significant breakthroughs in several key technical areas. These innovations collectively form the core competitiveness of the system:

* **Pioneering Three-Point Hand-Eye Calibration Method**: Breaks through the limitations of traditional hand-eye calibration methods that require specific patterns (like checkerboards), achieving high-precision calibration using only three spatial points. This innovation greatly simplifies the calibration process, reducing operational steps by 70%, and simultaneously boosting hand-eye calibration accuracy by 4 times, effectively ensuring sub-millimeter positioning accuracy of the robotic arm and improving deployment efficiency.
* **Multimodal Correlation Fusion Network**: Proposed and implemented an innovative "two-plus-one stream network" architecture. This network deeply integrates and jointly analyzes audio and visual feature matrices, performing cross-modal information fusion and correlation mining through complex neural network structures, thereby comprehensively enhancing the system's environmental perception, object recognition, and human-computer interaction intelligence, allowing it to understand complex scenarios more thoroughly.
* **Dynamic Obstacle Avoidance Algorithm Based on Real-time Visual Feedback**: Developed an advanced dynamic obstacle avoidance algorithm that continuously receives real-time visual feedback from the high-definition camera. Based on this, the robotic arm can online optimize its motion trajectory according to dynamic changes in the workspace (e.g., new obstacles, environmental changes), intelligently avoiding collisions, ensuring operational safety, robustness, and smoothness.
* **High-Performance Lightweight Model Deployment**: Successfully achieved lightweight optimization of complex deep detection models (like YOLOv8n) and their efficient deployment on the RDK X5 edge computing platform. This not only guarantees high-precision drug recognition accuracy (99.2%) but also achieves extremely fast inference speeds (22ms/frame) and low system power consumption (150W), meeting the stringent requirements for real-time performance and energy efficiency in actual pharmacy environments.
* **Flexible Modular Architecture Design**: The system adopts a highly decoupled modular design philosophy. This architecture ensures that each functional module is independent yet cooperates closely, greatly facilitating incremental learning and continuous updating of the medical knowledge base, and also supporting rapid replacement, upgrading, and maintenance of hardware components like robotic arms, significantly enhancing system scalability and lifecycle.
* **Enhanced Dialogue State Tracking and Logical Judgment**: Deeply integrated dialogue state tracking and complex logical judgment functionalities within the Large Language Model's LongChain (long-chain processing flow). This enables the system not only to understand the user's initial intent but also to remember historical dialogue context. Crucially, when necessary (e.g., user descriptions are vague, information is missing, or potential risks exist), it can proactively prompt the user for clarification, ensuring the accuracy, safety, and rigor of medication recommendations, providing a more humanized and intelligent interactive experience.

## üìä Key Performance Metrics

| Metric                        | Parameter  | Description                                                                                             |
| :---------------------------- | :--------- | :------------------------------------------------------------------------------------------------------ |
| Single Grasping Time          | 1.8¬±0.3s   | Average time from command issuance to completion of drug grasping by the robotic arm.                   |
| Positioning Accuracy          | 0.05mm     | Maximum error of the robotic arm's end-effector (suction pump) reaching a specified spatial position, demonstrating extreme precision. |
| System Power Consumption      | 150w       | Average power consumption of the entire system during stable, normal operation, reflecting energy efficiency. |
| Drug Recognition Accuracy     | 99.2%      | Percentage of correct drug identification by the visual system, ensuring the correctness of dispensing. |
| Visual Model Inference Speed  | 22ms/frame | Time taken by the visual model to process a single frame image and perform all target detection and recognition, ensuring real-time performance. |
| Path Planning Response Time   | <0.5s      | Response time from the robotic arm receiving a motion command to starting the generation and execution of the motion path, ensuring system fluidity. |
| Symptom Analysis Response Time | 0.8s       | Average time from the large language model receiving symptom descriptions to analyzing and providing initial recommendations. |
| Emergency Drug Interception Rate | 100%       | Percentage of complete successful interception and warning by the system when identifying potentially contraindicated, allergic, or incorrect drug recommendations; a critical safety guarantee. |

## üöÄ Future Outlook and System Scalability

Building upon its current powerful functionalities, this system possesses immense potential for further development into a "personalized intelligent medication terminal." Future expansion directions will focus on deeper levels of personalization, intelligence, and seamless, unattended service:

* **Integration of Biometric Recognition Modules**: In the future, the system can seamlessly integrate advanced biometric recognition modules such as fingerprint or facial recognition. This will enable rapid, secure user identity authentication and a truly "sense-free" interaction experience, moving beyond traditional authentication methods and significantly enhancing user convenience.
* **Deep Integration with Medical Big Data and Health Records**: The system will be capable of real-time access to local or cloud-based medical big data platforms, deeply integrating with patient electronic health records (EHR), detailed medication history, allergy information, genetic background, and other relevant health records. Based on this comprehensive individual health data, the system will be able to perform more intelligent drug screening, dosage adjustments, and precise grasping, providing highly customized, personalized dispensing services, minimizing adverse drug reactions.
* **Dynamic Health Modeling and Proactive Intervention**: By combining real-time user physiological data and health status monitored by smart wearable devices (e.g., smart bands, smart patches), the system can construct dynamic health models. Through the analysis of this real-time data, the system will be able to dynamically assess changes in user health conditions and proactively adjust medication plans, or even issue early warnings or suggestions when health indicators are abnormal.
* **Building a "Recognize-Understand-Execute" Closed-Loop Smart Medical Service**: The ultimate goal is to form a highly intelligent closed-loop service process: "Identity Recognition‚ÄîHealth Modeling‚ÄîPersonalized Dispensing‚ÄîIntelligent Grasping‚ÄîMedication Guidance." This will transform the system from merely a dispensing machine into an intelligent medical partner capable of continuous learning, adaptation, and proactive service to user health needs.

## üìö References

* [1]. A method and system for intelligent robotic arm operation based on multimodal large vision-language models:CN202510005797.2[P]. 2025-03-07.
* [2]. Study on the quality of drug vial recognition and grasping and opening for pharmacy intravenous admixture robot based on nanophotonic sensing,Guochun, Li et al.ÔºåSLAS Technology, Volume 31, 100244
* [3]. Shihao GeÔºåBeiping HouÔºåWen ZhuÔºåYangbin Zheng.(2023).Vision-based Robot Arm Grasping in Medical region.Highlights in Science Engineering and Technology,43:261-264.
* [4]. Dania Saad Rammal,Muaed Alomar,Subish Palaian.(2022).An Overview of the Current State and Perspectives of Pharmacy Robot and Medication Dispensing Technology.Cureus 14(8).
* [5]. KenMorrill.AI Robotic Pharmacy Dispensing: 20 Advances.Yenra.com,2025
* [6]. Dmitry Kalashnikov, Alex Irpan, Peter Pastor, Julian Ibarz, Alexander Herzog, Eric Jang, Deirdre Quillen, Ethan Holly, Mrinal Kalakrishnan, Vincent Vanhoucke, Sergey Levine.(2018).QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation.ArXiv:1806.10293.
* [7]. [https://github.com/TommyZihao/vlm_arm](https://github.com/TommyZihao/vlm_arm)
